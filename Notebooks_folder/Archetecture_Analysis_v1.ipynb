{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Tranformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Load the ViT feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 as required by ViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])\n",
    "\n",
    "# Custom Dataset class for loading images and labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])  # Ensure label is integer\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Label as long for CrossEntropyLoss\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize ViT model for binary classification\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Tracking metrics\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with tqdm\n",
    "num_epochs = 100\n",
    "best_val_auc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = correct_predictions / len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            val_correct_predictions += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_loss /= len(test_loader)\n",
    "    val_acc = val_correct_predictions / len(test_dataset)\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    # Save the model with the best AUC score\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'best_ViT_Test.pth')\n",
    "        print(f\"Model saved with best validation AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Plot Loss and Accuracy over Epochs\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/Notebooks/best_ViT_Test.pth'))\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate final metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# Print final evaluation metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Plotting metrics\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define image transformations for ResNet preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "# Custom Dataset class for loading images and labels with ResNet preprocessing\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])  # Ensure label is integer\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Label as long for CrossEntropyLoss\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize ResNet model for binary classification with two output labels\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = models.resnet50(pretrained=True)  # Use ResNet-50 pretrained model\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Modify final layer for binary classification\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for binary classification\n",
    "\n",
    "# Tracking lists for loss, accuracy, and AUC\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with tqdm\n",
    "num_epochs = 100\n",
    "best_val_auc = 0.0  # Track the best validation AUC\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # Get outputs for ResNet\n",
    "            loss = criterion(outputs, labels)  # Use logits directly\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training metrics\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)  # Get class predictions\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)  # Append training loss\n",
    "    train_acc = correct_predictions / len(train_dataset)\n",
    "    train_accuracies.append(train_acc)  # Append training accuracy\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.softmax(outputs, dim=1)[:, 1]  # Probability for class 1\n",
    "            val_correct_predictions += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate validation loss, accuracy, and AUC score\n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)  # Append validation loss\n",
    "    val_acc = val_correct_predictions / len(test_dataset)\n",
    "    val_accuracies.append(val_acc)  # Append validation accuracy\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_aucs.append(val_auc)  # Append AUC\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    # Save model if AUC improves\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'best_ResNet_AUC_Model.pth')\n",
    "        print(f\"Model saved with best validation AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "model.load_state_dict(torch.load('best_ResNet_AUC_Model.pth'))\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Get the predicted class label\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate final metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# Print final evaluation metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Plotting metrics\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN model with no specified archetecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # Assuming RGB images\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # self.fc1 = nn.Linear(32* 64 *64,128) # 256px\n",
    "        self.fc1 = nn.Linear(32 * 61 * 61, 128) # for 244 px\n",
    "        # self.fc1 = nn.Linear(32 * 80 * 80, 128)  #ffor 320 px Adjust this based on the output size\n",
    "        self.fc2 = nn.Linear(128, 1)  # Binary classification (output one value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize(244, antialias=True),\n",
    "    v2.RandomCrop(244),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create your own Dataset class to load images and labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['Surgery diagnosis in number']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load data and prepare for training\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()  # For binary classification\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "# Initialize best AUC variable\n",
    "best_val_auc = 0.0  # To keep track of the best validation AUC\n",
    "# Initialize lists to store loss and accuracy values\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_aucs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.float().to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training metrics\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.round(torch.sigmoid(outputs.squeeze()))\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Calculate average training loss and accuracy for the epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = correct_predictions / len(train_dataset)\n",
    "\n",
    "    # Append training loss and accuracy\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels.float().to(device))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.sigmoid(outputs.squeeze())  # Get probabilities\n",
    "            val_correct_predictions += (torch.round(predictions) == labels.float().to(device)).sum().item()\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate average validation loss, accuracy, and AUC for the epoch\n",
    "    val_loss /= len(test_loader)\n",
    "    val_acc = val_correct_predictions / len(test_dataset)\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "    # Append validation metrics\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Print metrics for this epoch\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    # Save the model if validation AUC improves\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'best_CNN_AUC_Model.pth')\n",
    "        print(f\"Model saved with best validation AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Plot Loss and Accuracy over Epochs\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training and Validation plots generated.\")\n",
    "# Final evaluation\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the best trained model is loaded\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_CNN_AUC_Model.pth'))  # Load the best model saved during training\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists for true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        predictions = torch.round(torch.sigmoid(outputs.squeeze()))  # Convert to binary predictions\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {roc_auc_score(y_true, y_pred):.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix and Classification Report\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax[0])\n",
    "ax[0].set_title(\"Confusion Matrix\")\n",
    "ax[0].set_xlabel(\"Predicted Labels\")\n",
    "ax[0].set_ylabel(\"True Labels\")\n",
    "ax[0].set_xticklabels(['Non-Cancer', 'Cancer'])\n",
    "ax[0].set_yticklabels(['Non-Cancer', 'Cancer'])\n",
    "\n",
    "# Generate and plot Classification Report as a DataFrame\n",
    "report_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer'], output_dict=True)).transpose()\n",
    "\n",
    "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap='YlGnBu', cbar=False, ax=ax[1], fmt='.2f')\n",
    "ax[1].set_title(\"Classification Report\")\n",
    "ax[1].set_xlabel(\"Metrics\")\n",
    "ax[1].set_ylabel(\"Classes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Testing completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficinet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define image transformations for ResNet preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "# Custom Dataset class for loading images and labels with ResNet preprocessing\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])  # Ensure label is integer\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Label as long for CrossEntropyLoss\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize ResNet model for binary classification with two output labels\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = models.efficientnet_b0(pretrained=True)  # Use EfficientNet-B0 pretrained model\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)  # Modify final layer for binary classification\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and criterion remain the same\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for binary classification\n",
    "\n",
    "# Tracking lists for loss, accuracy, and AUC\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with tqdm\n",
    "num_epochs = 100\n",
    "best_val_auc = 0.0  # Track the best validation AUC\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # Get outputs for ResNet\n",
    "            loss = criterion(outputs, labels)  # Use logits directly\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training metrics\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)  # Get class predictions\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)  # Append training loss\n",
    "    train_acc = correct_predictions / len(train_dataset)\n",
    "    train_accuracies.append(train_acc)  # Append training accuracy\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.softmax(outputs, dim=1)[:, 1]  # Probability for class 1\n",
    "            val_correct_predictions += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate validation loss, accuracy, and AUC score\n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)  # Append validation loss\n",
    "    val_acc = val_correct_predictions / len(test_dataset)\n",
    "    val_accuracies.append(val_acc)  # Append validation accuracy\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_aucs.append(val_auc)  # Append AUC\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    # Save model if AUC improves\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'EB0_Test_64_BS.pth')\n",
    "        print(f\"Model saved with best validation AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "model.load_state_dict(torch.load('EB0_Test_64_BS.pth'))\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Get the predicted class label\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate final metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# Print final evaluation metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Plotting metrics\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeiT (Data efficient image Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DeiTForImageClassification, DeiTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the DeiT feature extractor\n",
    "feature_extractor = DeiTFeatureExtractor.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])\n",
    "\n",
    "# Custom Dataset class for DeiT\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize DeiT model for binary classification\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = DeiTForImageClassification.from_pretrained(\n",
    "    \"facebook/deit-base-distilled-patch16-224\",\n",
    "    num_labels=2  # Set for binary classification\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training and validation metrics\n",
    "train_losses, val_losses, train_accuracies, val_accuracies, val_aucs = [], [], [], [], []\n",
    "num_epochs = 100\n",
    "best_val_auc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).logits  # Access logits for DeiT\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training metrics\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc = correct_predictions / len(train_dataset)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_labels, val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            val_correct_predictions += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc = val_correct_predictions / len(test_dataset)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    # Save model if AUC improves\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'best_DeiT_AUC_Model.pth')\n",
    "        print(f\"Model saved with best validation AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "model.load_state_dict(torch.load('best_DeiT_AUC_Model.pth'))\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate final metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# Print final evaluation metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Plotting metrics\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import timm  # For using Swin Transformer models\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define image transformations for Swin Transformer preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for Swin Transformer\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization\n",
    "])\n",
    "\n",
    "# Custom Dataset class for loading images and labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])  # Ensure label is integer\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize Swin Tiny Transformer for binary classification\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss for binary classification\n",
    "\n",
    "# Tracking lists for loss, accuracy, and AUC\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with tqdm\n",
    "num_epochs = 100\n",
    "best_val_auc = 0.0  # Track the best validation AUC\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc = correct_predictions / len(train_dataset)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            val_correct_predictions += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc = val_correct_predictions / len(test_dataset)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        torch.save(model.state_dict(), 'best_SwinTiny_AUC_Model.pth')\n",
    "        print(f\"Model saved with best validation AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "model.load_state_dict(torch.load('best_SwinTiny_AUC_Model.pth'))\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate and print final evaluation metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Plotting metrics\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test_loader from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define image transformations for ResNet preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "# Custom Dataset class for loading images and labels with ResNet preprocessing\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])  # Ensure label is integer\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Label as long for CrossEntropyLoss\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test transormer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DeiTForImageClassification\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Initialize DeiT model for binary classification\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_ViT_AUC_Model.pth'))  # Load the trained weights for ViT\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model.eval()\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images).logits\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "        probabilities = F.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (Cancer)\n",
    "\n",
    "        # Store labels, predictions, and probabilities\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics \n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Calculate and plot confusion matrix and classification report as image\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax[0])\n",
    "ax[0].set_title(\"Confusion Matrix\")\n",
    "ax[0].set_xlabel(\"Predicted Labels\")\n",
    "ax[0].set_ylabel(\"True Labels\")\n",
    "ax[0].set_xticklabels(['Non-Cancer', 'Cancer'])\n",
    "ax[0].set_yticklabels(['Non-Cancer', 'Cancer'])\n",
    "\n",
    "# Classification Report as Image\n",
    "report_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer'], output_dict=True)).transpose()\n",
    "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap='YlGnBu', cbar=False, ax=ax[1], fmt='.2f')\n",
    "ax[1].set_title(\"Classification Report\")\n",
    "ax[1].set_xlabel(\"Metrics\")\n",
    "ax[1].set_ylabel(\"Classes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the best trained model is loaded\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_cnn_model.pth'))  # Load the best model saved during training\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists for true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        predictions = torch.round(torch.sigmoid(outputs.squeeze()))  # Convert to binary predictions\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {roc_auc_score(y_true, y_pred):.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix and Classification Report\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax[0])\n",
    "ax[0].set_title(\"Confusion Matrix\")\n",
    "ax[0].set_xlabel(\"Predicted Labels\")\n",
    "ax[0].set_ylabel(\"True Labels\")\n",
    "ax[0].set_xticklabels(['Non-Cancer', 'Cancer'])\n",
    "ax[0].set_yticklabels(['Non-Cancer', 'Cancer'])\n",
    "\n",
    "# Generate and plot Classification Report as a DataFrame\n",
    "report_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer'], output_dict=True)).transpose()\n",
    "\n",
    "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap='YlGnBu', cbar=False, ax=ax[1], fmt='.2f')\n",
    "ax[1].set_title(\"Classification Report\")\n",
    "ax[1].set_xlabel(\"Metrics\")\n",
    "ax[1].set_ylabel(\"Classes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Testing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths\n",
    "data_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/Thyroid_Cancer_TAN&NOH_file.csv'\n",
    "base_image_path = '/home/iambrink/NOH_Thyroid_Cancer_Data/'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(subset=['Surgery diagnosis in number'])  # Drop rows with NaN labels\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define image transformations for EfficientNet-B0 preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for EfficientNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for EfficientNet\n",
    "])\n",
    "\n",
    "# Custom Dataset class for loading images and labels with EfficientNet preprocessing\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx]['Surgery diagnosis in number'])  # Ensure label is integer\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Label as long for CrossEntropyLoss\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for deterministic results\n",
    "\n",
    "# Load the saved model checkpoint\n",
    "model = models.efficientnet_b0(pretrained=False)  # Initialize EfficientNet-B0 model\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)  # Modify the final layer\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_EfficientNet_AUC_Model_NOH_ONLY.pth'))  # Load the trained weights\n",
    "model = model.to(device)  # Move model to GPU if available\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (cancer)\n",
    "\n",
    "        # Store labels and predictions\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)  # For binary classification, use `pos_label=1` for Cancer\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import DeiTForImageClassification  # Import DeiT model\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for deterministic results\n",
    "\n",
    "# Load the saved DeiT model checkpoint\n",
    "model = DeiTForImageClassification.from_pretrained('facebook/deit-base-distilled-patch16-224', num_labels=2)\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_DeiT_AUC_Model_TAN_ONLY.pth'))  # Load the trained weights\n",
    "model = model.to(device)  # Move model to GPU if available\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images).logits  # Use `.logits` to get the output logits from DeiT\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (Cancer)\n",
    "\n",
    "        # Store labels and predictions\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)  # For binary classification, use `pos_label=1` for Cancer\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import timm\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for deterministic results\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the Swin Tiny model\n",
    "model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=2)  # Initialize Swin Tiny with binary classification\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_Swin_AUC_Model_NOH_ONLY.pth'))  # Load the trained weights\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (Cancer)\n",
    "\n",
    "        # Store labels and predictions\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)  # For binary classification, use `pos_label=1` for Cancer\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import timm\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for deterministic results\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the ResNet-50 model\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=2)  # Initialize ResNet-50 with binary classification\n",
    "model.load_state_dict(torch.load('best_ResNet_AUC_Model_TAN_ONLY.pth'))  # Load the trained weights for ResNet-50\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (Cancer)\n",
    "\n",
    "        # Store labels and predictions\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)  # For binary classification, use `pos_label=1` for Cancer\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for deterministic results\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the ViT model\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_ViT_AUC_Model.pth'))  # Load the trained weights for ViT\n",
    "model = model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images).logits  # .logits to access the raw predictions\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Predicted class labels\n",
    "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (Cancer)\n",
    "\n",
    "        # Store labels and predictions\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)  # For binary classification, use `pos_label=1` for Cancer\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # Assuming RGB images\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # self.fc1 = nn.Linear(32* 64 *64,128) # 256px\n",
    "        self.fc1 = nn.Linear(32 * 61 * 61, 128) # for 244 px\n",
    "        # self.fc1 = nn.Linear(32 * 80 * 80, 128)  #ffor 320 px Adjust this based on the output size\n",
    "        self.fc2 = nn.Linear(128, 1)  # Binary classification (output one value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# Load the dataset using ImageFolder\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize(244, antialias=True),\n",
    "    v2.RandomCrop(244),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create your own Dataset class to load images and labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, base_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.base_path, self.dataframe.iloc[idx]['image_path'].replace('\\\\', '/'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['Surgery diagnosis in number']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disable for deterministic results\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_df, base_image_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, base_image_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the simple CNN model\n",
    "model = SimpleCNN().to(device)\n",
    "model.load_state_dict(torch.load('/home/iambrink/NOH_Thyroid_Cancer_Data/best_CNN_AUC_Model_NOH_ONLY.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images).squeeze()  # Get outputs and remove extra dimension\n",
    "        probabilities = torch.sigmoid(outputs)  # Probability for class 1 (Cancer)\n",
    "        predictions = (probabilities >= 0.5).int()  # Binary predictions based on threshold\n",
    "\n",
    "        # Store labels and predictions\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_prob.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)  # For binary classification, use `pos_label=1` for Cancer\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancer', 'Cancer']))\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"  ROC-AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
